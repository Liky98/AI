{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Reuters.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPAFVn0Y1JgG6e+Gnn+KgSS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"lu5vcYSkWJHm"},"source":["from keras.datasets import reuters\n","\n","(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000)\n","#로이터 데이터셋 가져오고 각 데이터를 변수에 넣어줌"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ue2-BzD4WkZw"},"source":["#훈련용데이터와 검증용 데이터 몇개로 분류되었는지 출력.\n","print(len(train_data))\n","print(len(test_data))\n","\n","print(train_data[1]) #2차원 배열로 들어가있음\n","print(train_labels[0]) #1차원 배열로 들어가있음."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"feX9Oc9ZzLmN"},"source":["import numpy as np\n","\n","def vectorize_sequences ( sequences, dimension = 10000):\n","    results = np.zeros((len(sequences), dimension)) #입력데이터만큼의 열을 만들고 각 행의 크기는 10000으로 설정, 값은 0으로 2차원배열만듬\n","    for i, sequence in enumerate(sequences) : #i는 0,1,2,...처럼 순서. sequnce는 입력데이터의 순서별 각 원소값\n","        results[i,sequence] = 1. #0번째 행의 0번째 원소값 열에 값에 실수형 1.00 삽입\n","    return results\n","# 이 함수를 통해 안에 값이 있으면 1, 값이 없으면 0으로 정규화를 시켜줬음\n","\n","x_train = vectorize_sequences(train_data)\n","x_test = vectorize_sequences(test_data)\n","\n","#확인\n","print(len(x_train))\n","print(len(x_test))\n","\n","print(len(x_train[0]))\n","print(x_train[0])\n","print(len(x_test[0]))\n","print(x_test[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7L9Om8NWzVYh"},"source":["import keras\n","one_hot_train_labels = keras.utils.to_categorical(train_labels)\n","one_hot_test_labels = keras.utils.to_categorical(test_labels)\n","\n","print(len(one_hot_train_labels)) #디멘션이 46임\n","print(len(one_hot_test_labels[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RJB40VrhmFO6"},"source":["train_data와 test_data는 파이썬 리스트의 넘파이 배열이기 때문에 to_categorical() 함수를 사용하지 못합니다. x_train과 x_test의 크기는 각각 (8982, 10000), (2246, 10000)이 되고 one_hot_train_labels와 one_hot_test_labels의 크기는 각각 (8982, 46), (2246, 46)이 됩니다."]},{"cell_type":"code","metadata":{"id":"IKKA30Vz2N-7"},"source":["from keras import models\n","from keras  import layers\n","\n","model = models.Sequential()\n","model.add(layers.Dense(64, activation='relu', input_shape = (10000,)))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(46, activation='softmax')) # 각 입력 샘플에 대해서 46차원의 벡터를 출력 / 이 벡터의 각 원소(각 차원)는 각기 다른 출력 클래스가 인코딩된 것 / 확률 분포\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Wa_B2lNn7dq"},"source":["• 마지막 Dense 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)는 각기 다른 출력 클래스가 인코딩된 것입니다.\n","\n","• 마지막 층에 softmax 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉 46차원의 출력 벡터를 만들며 output[i]는 어떤 샘플이 클래스 i에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다."]},{"cell_type":"code","metadata":{"id":"DqTI0nlvn8_W"},"source":["model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OV47CAXzoFrJ"},"source":["이런 문제에 사용할 최선의 손실 함수는 categorical_crossentropy입니다. 이 함수는 두 확률 분포 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."]},{"cell_type":"code","metadata":{"id":"AlSJ7PgyoqJR"},"source":["x_val = x_train[:1000] #뒤에서 천개 때서 검증용 데이터로 사용\n","partial_x_train = x_train[1000:] #7982개.\n","y_val = one_hot_train_labels[:1000]\n","partial_y_train = one_hot_train_labels[1000:]\n","\n","history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDNBcYvOpKYZ"},"source":["import matplotlib.pyplot as plt\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(loss) + 1)\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend() #하나의 그래프안에 그리기?\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yiKss1xxrDe6"},"source":["plt.clf()\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bAL5q6ytrqiR"},"source":["model = models.Sequential()\n","model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(46, activation='softmax'))\n","\n","\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(partial_x_train,\n","          partial_y_train,\n","          epochs=9,\n","          batch_size=512,\n","          validation_data=(x_val, y_val))\n","results = model.evaluate(x_test, one_hot_test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOCoMp5Nr5Tq"},"source":["print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tFryJZ-8sHMT"},"source":["대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 18% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다.\n","\n",">>> import copy\n",">>> test_labels_copy = copy.copy(test_labels)\n",">>> np.random.shuffle(test_labels_copy)\n",">>> hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",">>> float(np.sum(hits_array)) / len(test_labels)\n","0.182546749777382"]}]}