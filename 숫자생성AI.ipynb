{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"숫자생성AI.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["mhNXncbGoj-A","sx2-D6yspEM4","TnxheFYuusf4"],"authorship_tag":"ABX9TyMNgwDpIECSByey1EOq5Sox"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mhNXncbGoj-A"},"source":["#숫자 생성 인공지능 원리\r\n"]},{"cell_type":"markdown","metadata":{"id":"Td4ycruhojdR"},"source":["생성 신경망 중 GAN을 이용함.\r\n","\r\n","GAN (Generative Adversarial Network)\r\n","- 적대적 생성 신경망.\r\n","\r\n","2개의 신경망으로 이루어져 있음.\r\n","**판별자 신경망**과 **생성자 신경망.**\r\n","- 생성자는 진짜같은 가짜를 생성함.\r\n","- 판별자는 진짜그림과 생성자가 만든 가짜 그림을 구별 가능.\r\n","\r\n","두 신경망은 목표가 있음.\r\n","- 생성자 : 판별자가 자신이 만든 그림을 진짜처럼 생각할 정도의 그림을 그림.\r\n","- 판별자 : 생성자가 만든 그림을 진짜인지 가짜인지 전부 구별해야함.\r\n","\r\n","이제 두 신경망은 서로 이기기 위해 학습을 시작함.\r\n","\r\n","이렇게 두 개의 신경망을 사용하여 이러한 원리로 생성해 내는 기법이 **GAN(적대적 생성 신경망)**임.\r\n"]},{"cell_type":"markdown","metadata":{"id":"sx2-D6yspEM4"},"source":["#개발 환경 세팅"]},{"cell_type":"code","metadata":{"id":"RGCGGDzipDpP"},"source":["from keras.models import Model, Sequential\r\n","from keras.layers import Dense, Input\r\n","from keras.layers.advanced_activations import LeakyReLU\r\n","from keras.optimizers import Adam\r\n","from keras.datasets import mnist\r\n","\r\n","from tqdm import tqdm\r\n","import numpy\r\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Efoq0rJqaTw"},"source":["```\r\n","from keras.models import Model, Sequential \r\n","```\r\n",">모델 도구중에 모델과 시퀀셜 모델함수를 불러옴.GAN은 두개의 신경망이 필요하고, 이 두 신경망은 모두 시퀀셜 형태이기에 필요함.\r\n","\r\n","\r\n","```\r\n","from keras.layers.advanced_activations import LeakyReLU\r\n","```\r\n",">렐루함수와 Leaky렐루함수의 차이점\r\n","- 렐루함수 : 0보다 작은 값 들어오면 0을 반환.\r\n","- Leaky렐루 : 0보다 작은 값 들어오면 음수의 값 반환.\r\n","\r\n","\r\n","\r\n","```\r\n","from keras.optimizers import Adam\r\n","```\r\n","> 학습한 모델의 오차 줄이기 위해 경사하강법 사용. 이때 사용하는 옵티마이저는 아담 옵티마이저.\r\n","\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"TnxheFYuusf4"},"source":["#데이터 불러오기.\r\n"]},{"cell_type":"code","metadata":{"id":"-PiZznP4u22o"},"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n","print(len(x_train))\r\n","print(len(y_train))\r\n","print(len(x_test))\r\n","print(len(y_test))\r\n","\r\n","x_train = (x_train.astype(numpy.float32) - 127.5)/127.5\r\n","mnist_data = x_train.reshape(60000,784)\r\n","print(mnist_data.shape)\r\n","len(mnist_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vOz45yAjuxfg"},"source":["mnist의 데이터에는 훈련용데이터와 검증용 데이터가 있고 각 6만개, 1만개가 있음.\r\n","\r\n","훈련용데이터 6만개를 data로 사용할 것임.\r\n","\r\n","\r\n","\r\n","```\r\n","x_train = (x_train.astype(numpy.float32) - 127.5)/127.5\r\n","```\r\n",">일단 데이터의 정규화를 위해 -1 ~ 1 사이의 값으로 만들어줌.\r\n","mnist 데이터셋의 그림은 0~ 255까지의 숫자로 이루어져 있어서 127.5를 빼고 127.5로 나누어주면 0은 -1로, 255는 1로 만들어줌.\r\n","정규화끝\r\n","\r\n","\r\n","\r\n","\r\n","```\r\n","mnist_data = x_train.reshape(60000,784)\r\n","```\r\n",">mnist데이터는 28* 28개의 픽셀데이터로 이루어져 있음.\r\n","그래서 한줄로 넣기위해 784 * 1로 설정함.\r\n"]},{"cell_type":"markdown","metadata":{"id":"9thXs6xD10da"},"source":["#생성자 신경망 제작"]},{"cell_type":"code","metadata":{"id":"ankp-ovA4j9b"},"source":["def create_generator():\r\n","    generator = Sequential()\r\n","    generator.add(Dense(units=256, input_dim=100))\r\n","    generator.add(LeakyReLU(0.2))\r\n","    generator.add(Dense(units=512))\r\n","    generator.add(LeakyReLU(0.2))\r\n","    generator.add(Dense(units=784, activation='tanh'))\r\n","    return generator\r\n","g= create_generator()\r\n","g.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RDatmhvf121p"},"source":["input_dim 은 입력 형태.\r\n","시퀀셜모델을 사용함.(순차적으로 레이어를 쌓음)\r\n","\r\n","\r\n","\r\n","```\r\n"," generator.add(Dense(units=256, input_dim=100))\r\n","```\r\n","> input_dim 입력뉴런의 수를 100개로 설정. 신경망의 첫번째 층은 256개의 노드로 설정.\r\n","100을 설정해서 100개의 픽셀값이 랜덤한 값을 가짐.(노이즈값)\r\n","\r\n","\r\n","\r\n","```\r\n"," generator.add(LeakyReLU(0.2))\r\n","```\r\n","> 활성화함수를 leakyRelu로 설정. 음수값은 특정한 기울기를 보이는데, 이 기울기의 값을 0.2로 설정하는것.\r\n","\r\n","\r\n","tanh : 하이퍼볼릭탄젠트 함수.\r\n","마지막 출력층은 현재 mnist 데이터 모습이 1*784로 되어있어서 784개의 픽셀을 나열한 모습으로 나타내야하기에 784로 설정.\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"zlIrnMEXPX3o"},"source":["#판별자 신경망 제작"]},{"cell_type":"code","metadata":{"id":"LbuuAgVwPb0O"},"source":["def create_discriminator():\r\n","    discriminator = Sequential()\r\n","    discriminator.add(Dense(units=512, input_dim=784))\r\n","    discriminator.add(LeakyReLU(0.2))\r\n","    discriminator.add(Dense(units=256))\r\n","    discriminator.add(LeakyReLU(0.2))\r\n","    discriminator.add(Dense(units=1, activation='sigmoid'))\r\n","    discriminator.compile(loss = 'binary_crossentropy', optimizer = Adam(lr=0.002, beta_1=0.5))\r\n","    return discriminator\r\n","d = create_discriminator()\r\n","d.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RmZbY-KUPZ2O"},"source":["입력뉴런의 수, input_dim은 생성자가 만든 글씨가 784픽셀로 이루어져있기에 입력값을 784로 설정.\r\n","\r\n","촤종출력 노드는 1개. 진짜글씨면 1, 생성자가 만든 가짜글씨면 0.\r\n","\r\n","\r\n","\r\n","```\r\n","discriminator.compile(loss = 'binary_crossentropy', optimizer = Adam(lr=0.002, beta_1=0.5))\r\n","```\r\n",">둘 중 하나 고르는 문제이니 오차값(loss)은 이항교차 엔트로피 사용.\r\n","학습속도(학습률)인 lr 은 0.002로, 베타 최적화 값은 0.5로 설정.\r\n","\r\n","(여기서 학습속도, 학습률은 경사하강법에서 오차가 작아지는 방향으로 가중치의 값을 이동할 때, 한번에 얼만큼의 크기로 이동할 것인지를 뜻함.)\r\n"]},{"cell_type":"markdown","metadata":{"id":"86YdQUhbRuze"},"source":["#GAN 생성 함수 제작"]},{"cell_type":"markdown","metadata":{"id":"w4CkfACjacOz"},"source":["생성자 신경망과 판별자 신경망을 제작했으니 GAN을 만듬."]},{"cell_type":"code","metadata":{"id":"8SoREJ11RkKJ"},"source":["def create_gan(discriminator, generator) :\r\n","    discriminator.trainable = False\r\n","    gan_input = Input(shape = (100,))\r\n","    x = generator(gan_input)\r\n","    gan_output = discriminator(x)\r\n","    gan = Model(inputs = gan_input, outputs = gan_output)\r\n","    gan.compile(loss='binary_crossentropy', optimizer = 'adam')\r\n","    return gan\r\n","\r\n","gan = create_gan(d,g)\r\n","gan.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7SM519f64riR"},"source":["create_gan 함수는 인자값 두개, 판별자와 생성자를 입력받음.\r\n","\r\n","   ` discriminator.trainable = False`\r\n","이건 판별자가 학습하지 못하게 막는 코드임.\r\n","\r\n","`input`은 입력할 데이터의 모습을 정하는 코드임. 콤마 `,` 뒤에 빈 곳은 자동으로 실제 총 데이터의 개수를 자동으로 넣어줌. 아까 60000개 설정했으니 6만을 자동으로 넣어줌.\r\n","\r\n","입력값은 생성자 신경망이 만든 그림, 출력값은 판별자 신경망이 판단한 결과임.\r\n","\r\n","- 입력층은 노이즈값이 100개의 픽셀값이 들어감.\r\n","- 두번째 레이어는 생성자 신경망에서 출력된 값의 모습\r\n","- 세번째 출력층은 가짜인지 진짜인지 판단한 결과.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"YWq2yKDK6LQI"},"source":["#결과 확인 함수 제작"]},{"cell_type":"markdown","metadata":{"id":"OgBdpNAV6Ry-"},"source":["만든 신경망들을 훈련시키고 정확도를 확인해야함.\r\n"]},{"cell_type":"code","metadata":{"id":"EBWuK9gy6aMv"},"source":["def plot_generated_images(generator) :\r\n","    noise = numpy.random.normal(loc=0, scale=1, size=[100,100])\r\n","    generated_images = generator.predict(noise)\r\n","    generated_images = generated_images.reshape(100,28,28)\r\n","\r\n","    plt.figure(figsize=(10,10))\r\n","    for i in range(generated_images.shape[0]) :\r\n","        plt.subplot(10,10, i+1)\r\n","        plt.imshow(generated_images[i], interpolation='nearest')\r\n","        plt.axis('off')\r\n","    plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mO4TD8Nr9OaL"},"source":["`def plot_generated_images(generator)` 파라미터는 어떤 생성자로 그릴지 설정.\r\n","\r\n","`noise = numpy.random.normal(loc=0, scale=1, size=[100,100])`\r\n","생성자에 넣어줄 노이즈 값. 균일한 값을 생성하도록 정규 분포 함수 `normal`사용.\r\n","첫번째 인자값은 평균이 0, 두번째 인자값 1은 평균에서 얼만큼 떨어져 있는지 (-1 ~ 1 사이의 값), 마지막 인자값은 노이즈 100개 생성하고 각 노이즈는 숫자 100개씩으로 구성되어있다는 뜻.\r\n","\r\n","즉 함수를 호출할 때마다 100개의 그림을 그려달라는 명령이다.\r\n","\r\n","`    generated_images = generator.predict(noise)` generated도 신경망 모델이기에 앞에서 만든 노이즈값을 신경망에 넣어서 예측하라는 명령.\r\n","\r\n","`    generated_images = generated_images.reshape(100,28,28)` 그림의 형태가  1 * 784의 형태이기에 28 * 28 사이즈로 바꿈.\r\n","\r\n","`    plt.figure(figsize=(10,10))` 그림의 크기는 10 * 10으로 설정.\r\n","\r\n","`    for i in range(generated_images.shpae[0]) ` 100개의 그림이니 100번 반복.\r\n","\r\n","\r\n","`        plt.subplot(10,10, i+1)` 위치를 지정해주고,\r\n","\r\n"," ` plt.imshow(generated_images[i], interpolation='nearest')` 이미지를 출력함. `interpolation`함수는 그림을 출력할 때, 각 픽셀을 어떻게 나타낼지 결정함. i번째 그림의 위치는 `generated_images[i]`에 넣음\r\n","\r\n","`plt.axis('off')` 그림 이름은 넣지 않음.\r\n","`plt.tight_layout()` 그림 화면에 출력."]},{"cell_type":"markdown","metadata":{"id":"KPWkhx7M_Ri0"},"source":["#GAN 훈련"]},{"cell_type":"code","metadata":{"id":"LJZyfzm9YVvI"},"source":["batch_size = 128\r\n","epochs = 5000\r\n","for e in tqdm(range(epochs)) :\r\n","    noise = numpy.random.normal(0,1,[batch_size, 100])\r\n","    generated_images = g.predict(noise)\r\n","    image_batch = mnist_data[numpy.random.randint(low=0, high= mnist_data.shape[0], size = batch_size)]\r\n","    \r\n","    x = numpy.concatenate([image_batch, generated_images])\r\n","\r\n","    y_dis = numpy.zeros( 2* batch_size)\r\n","    y_dis[:batch_size] = 1\r\n","\r\n","    d.trainable = True\r\n","    d.train_on_batch(x, y_dis)\r\n","    \r\n","    noise = numpy.random.normal(0,1, [batch_size, 100])\r\n","    y_gen = numpy.ones(batch_size)\r\n","    d.trainable = False\r\n","    gan.train_on_batch(noise, y_gen)\r\n","    if e==0 or e % 1000 == 0 :\r\n","        plot_generated_images(g)   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-yCAPGfH_RP6"},"source":["`batch_size` = 128로 설정.\r\n","`epochs` = 총 5000번 돌도록 설정.\r\n","\r\n","`tqdm()`은 진행과정을 시각화하여 보여주는 라이브러리. 진행표시바이다.\r\n","\r\n","`noise = numpy.random.normal(0,1,[batch_size, 100])` \r\n",">생성자에게 줄 노이즈값 정규분포함수사용하여 `batch_size`만큼의 개수만큼 생성. 생성된 각 데이터는 숫자 100개로 구성되어 있다는 의미.\r\n","\r\n","`generated_images = g.predict(noise)` \r\n",">생성자 신경망 모델에 노이즈를 입력하여 그림을 그리도록 만드는 명령어.(학습)\r\n","\r\n","\r\n","`image_batch = mnist_data[numpy.random.randint(low=0, high= mnist_data.shape[0], size = batch_size)]` \r\n",">mnist 데이터셋이 현재 6만개로 설정해 놓았는데 이중에서 `batch_size` 개수(128개)만 랜덤으로 뽑아서 가져옴. 학습할 때 마다 다양한 모양의 손글씨를 학습할 수 있게 설정한 것. 첫번째(low=0)부터 mnist_data.shape[0](mnist데이터셋 개수) 에서 batch_size만큼만 랜덤으로 고름.\r\n","\r\n","`x = numpy.concatenate([image_batch, generated_images])`\r\n",">`numpy`라이브러리에서 `concatenate`는 합치는 함수임 진짜그림과 가짜그림을 한줄로 붙게 만들어서 x에 넣음. 각 그림은 128개만큼 있으니 x는 총 256개의 데이터로 이루어져있음. 각 데이터에는 -1 ~ 1 사이의 값이 784개씩 들어있음.\r\n","\r\n","\r\n","\r\n","`y_dis = numpy.zeros( 2* batch_size)`로 256개의 데이터 값을 0으로 만들어주고, \r\n","`y_dis[:batch_size] = 1`로 이중 첫번째로 들어온 데이터 128개만 값을 1로 설정해줌.\r\n","이제 판별자는 처음나오는 128개의 데이터는 진짜, 나중에 들어온 128개는 가짜라는 것을 알 수 있음.\r\n","(distinguish = 구별하다)\r\n","\r\n","\r\n","`d.trainable = True` 판별자 신경망이 학습할 수 있도록(True) 설정.\r\n","\r\n","`d.train_on_batch(x, y_dis)` 신경망을 학습시킴. 입력데이터값은 x, 출력데이터값은 y_dis로 설정. 이제 입력데이터를 주면 판별자를 통해 나온 출력값과 정답 데이터의 결과값을 비교하여 오차를 줄일 수 있음.\r\n","\r\n","판별자는 학습을 시켰으니, 이제 생성자를 학습시킴.\r\n","\r\n","\r\n","`noise = numpy.random.normal(0,1, [batch_size, 100])` 새로운 노이즈값 생성.\r\n","\r\n","\r\n","`y_gen = numpy.ones(batch_size)` gan에 넣어줄 값을 모두 1로 설정. 가짜그림과 진짜그림 모두 진짜로 오해하도록 만듬.\r\n","\r\n","`d.trainable = False` 판별자의 학습을 그만시킴. 학습하지 않고 판단만 함.\r\n","\r\n","`gan.train_on_batch(noise, y_gen)` gan에 노이즈값을 입력데이터로 넣고 출력값을 모두 진짜라고 하고 넣어서  학습시킴.\r\n","이러면 GAN은 판별자가 진짜 그림이라고 생각할수 있게 생성자를 훈련시킴. \r\n","\r\n","판별자 신경망을 거쳐서 나온 값과 y_gen과 비교하면서 판별결과가 1이 나올 때 까지 생성자를 학습시킴. \r\n","\r\n","`if e==0 or e % 1000 == 0 :`\r\n","  `plot_generated_images(g) ` 첫번째 에포크와 각 1000단위의 에포크일때 생성자가 만든 그림을 출력함. \r\n"]}]}