{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM텍스트생성.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMxZf1+NA1AcUJRvVig1Z6r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iSOVkytNvWzZ"},"source":["import pandas as pd\n","import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import re\n","import urllib.request\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qjsR3Suvdzp"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjkBosehvkzm"},"source":["data = pd.read_table('ratings.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5HvYZVVvuQz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b0WHhx5LvXGR"},"source":[""]},{"cell_type":"code","metadata":{"id":"kPN6IYLJoPxQ"},"source":["import keras\n","import numpy as np\n","import tensorflow\n","\n","path = tensorflow.keras.utils.get_file(\n","    'ratings.txt',\n","    origin='https://github.com/e9t/nsmc/blob/master/ratings.txt')\n","text = open(path).read()\n","print('말뭉치 크기:', len(text))\n","type(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4uoRqvFhpWL5"},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ww-DQ9YgwzdF"},"source":["data['document'] = data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n","# 한글과 공백을 제외하고 모두 제거\n","data[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jd9bEh6hxI5n"},"source":["data['document'] = data['document'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n","data['document'].replace('', np.nan, inplace=True)\n","print(data.isnull().sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T27jtEtSxQ7g"},"source":["data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n","data['document'] = data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n","data['document'] = data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n","data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n","data = data.dropna(how='any') # Null 값 제거\n","print('전처리 후 테스트용 샘플의 개수 :',len(data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AgMPdtvwxj1u"},"source":["data['document'][30000:30020]\n","#print(type(data['document']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MiKQzh1Wo52x"},"source":["# 60개 글자로 된 시퀀스를 추출\n","maxlen = 60\n","\n","# 두 글자씩 건너 뛰면서 새로운 시퀀스를 샘플링\n","step = 3\n","\n","# 추출한 시퀀스를 담을 리스트\n","sentences = []\n","\n","# 타깃(시퀀스 다음 글자)을 담을 리스트\n","next_chars = []\n","\n","for i in range(0, len(data['document']) - maxlen, step) :\n","    sentences.append(data['document'][i: i + maxlen])\n","    \n","    next_chars.append(data['document'][i + maxlen])\n","print('시퀀스 개수:', len(sentences))\n","\n","# 말뭉치에서 고유한 글자를 담은 리스트\n","chars = sorted(list(set(data['document'])))\n","print('고유한 글자:', len(chars))\n","# chars 리스트에 있는 글자와 글자의 인덱스를 매핑한 딕셔너리\n","char_indices = dict((char, chars.index(char)) for char in chars)\n","\n","# 글자를 원-핫 인코딩하여 0과 1의 이진 배열로 바꿉니다.\n","print('벡터화...')\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","\n","print(\"x = \", x)\n","print(\"y = \", y)\n","\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1\n","\n","print(\"x = \", x)\n","print(\"y = \", y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qh2f3kRhrP3h"},"source":["from keras import layers\n","\n","model = keras.models.Sequential()\n","model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n","model.add(layers.Dense(len(chars), activation='softmax'))\n","\n","\n","optimizer = keras.optimizers.RMSprop(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UtLPERjar6Z_"},"source":["def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxlLmvMDsXK9"},"source":["import random\n","import sys\n","\n","random.seed(42)\n","start_index = random.randint(0, len(text) - maxlen - 1)\n","\n","# 60 에포크 동안 모델을 훈련합니다\n","for epoch in range(1, 60):\n","    print('에포크 : ', epoch)\n","    # 데이터에서 한 번만 반복해서 모델을 학습합니다\n","    model.fit(x, y, batch_size=128, epochs=1)\n","\n","    # 무작위로 시드 텍스트를 선택합니다\n","    seed_text = text[start_index: start_index + maxlen]\n","    print('--- 시드 텍스트: \"' + seed_text + '\"')\n","\n","    # 여러가지 샘플링 온도를 시도합니다\n","    for temperature in [0.2, 0.5, 1.0, 1.2]:\n","        print('------ 온도:', temperature)\n","        generated_text = seed_text\n","        sys.stdout.write(generated_text)\n","\n","        # 시드 텍스트에서 시작해서 400개의 글자를 생성합니다\n","        for i in range(400):\n","            # 지금까지 생성된 글자를 원-핫 인코딩으로 바꿉니다\n","            sampled = np.zeros((1, maxlen, len(chars)))\n","            for t, char in enumerate(generated_text):\n","                sampled[0, t, char_indices[char]] = 1.\n","\n","            # 다음 글자를 샘플링합니다\n","            preds = model.predict(sampled, verbose=0)[0]\n","            next_index = sample(preds, temperature)\n","            next_char = chars[next_index]\n","\n","            generated_text += next_char\n","            generated_text = generated_text[1:]\n","\n","            sys.stdout.write(next_char)\n","            sys.stdout.flush()\n","        print()"],"execution_count":null,"outputs":[]}]}