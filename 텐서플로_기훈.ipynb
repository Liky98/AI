{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"텐서플로_기훈.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOQ5Og+0khAIfgbueOBYxsw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"k7M7hGlmaTUx"},"source":["%tensorflow_version \r\n","#텐서플로우 라이브러리 설치되어있는지 확인."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4x3oh4F9foG"},"source":["# 데이터셋 설정"]},{"cell_type":"code","metadata":{"id":"wYdhW4kDcwpd"},"source":["import keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"80Qzx1dkcziA"},"source":["케라스는 텐서플로를 이용하기 더 쉽게만들어주는 도구임.\r\n","심층 신경망을 만들기 위한 텐서플로, 테아노, CNTK와 같은 도구를 더욱 쉽게 사용할 수 있게 도와주는 도구임.\r\n","따라서 케라스를 사용하려면 텐서플로 라이브러리를 불러온 상태여야함.\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"72er6vujMpQa"},"source":["from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.layers import Dense, Activation\r\n","from tensorflow.keras.utils import to_categorical\r\n","from tensorflow.keras.datasets import mnist\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Rnxj4ecQJ_S"},"source":["\r\n","from tensorflow.keras.models import Sequential\r\n","\r\n","기본적인 인공 신경망은 레이어가 순차적으로 구성되어 있음.\r\n","\r\n","이렇게 순차적인 신경망을 구성할 때 사용할 수 있는 함수가 케라스의 모델 도구 중 시퀀셜 모델 함수이다.\r\n"]},{"cell_type":"markdown","metadata":{"id":"4uhaBLSbQ98e"},"source":["Dense는 전결합층(fully-cinnected layer) 의미. 입력층 은닉층 출력층 과 같은 각 층의 바로 앞의 층과 서로 연결되어 있는 것이 전결합층이라함.\r\n","\r\n","Dense를 사용하여 각 레이어의 뉴런 개수를 설정할 수 있고,\r\n","\r\n","Activation은 활성화 함수를 의미함.\r\n"]},{"cell_type":"markdown","metadata":{"id":"zUKsUfaIWwJX"},"source":["유틸 도구중에  to_categorical라는 함수를 불러오는 명령어로, 원-핫 인코딩을 구현할 수 있는 함수임.\r\n","\r\n","여기서 one-hot incoding은 하나의 값만 1로 나타내고 나머지 값들은 전부 0 으로 표시하는 방법이다. 정답레이블을 첫번째, 두번째, ... 와 같이 순서로 나타내도록 데이터의 혀태를 바꾸는 것."]},{"cell_type":"markdown","metadata":{"id":"-FYmDgo8Xycl"},"source":["케라스를 사용히여 딥러닝 모델 개발을 연습할 수 있는 데이터가 여러개 있음.\r\n","그 데이터들은 데이터셋 도구(datasets)에 있음. mnist는 데이터셋을 불러오는 명령어.\r\n","\r\n","mnist 는 직접 손으로 쓴 숫자 db이다. \r\n","\r\n","훈련데이터와 검증데이터로 구성되어있음.\r\n"]},{"cell_type":"markdown","metadata":{"id":"fcWYSx_DYJfP"},"source":["numpy는 수학, 배열등 계산 라이브러리. as는 에일리어싱으로 별명 별칭임. 앞으로 np라 부르겠다는 뜻임."]},{"cell_type":"markdown","metadata":{"id":"ENs6UaqrYQyQ"},"source":["matplotlib는 그래프 라이브러리임. 막대그래프나 꺽은선그래프, 히스토그램등 다양한 그래프를 쉽게 그릴 수 있게 만든 함수로, 그중에서 그림을 그리는 pyplot을 사용하고 이걸 plt라 부르겠다는 뜻이다."]},{"cell_type":"code","metadata":{"id":"1uYXbCMbDtHx"},"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n","print(x_train.shape)\r\n","print(y_train.shape)\r\n","print(x_test.shape)\r\n","print(y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SeEkUE7ZIK-R"},"source":["load_data() 는 mnist 데이터셋에서 데이터를 불러오라는 명령임.\r\n","\r\n","mnist 데이터는 4부분으로 나누어져 있음. 이 값들을 numpy 라이브러리를 사용하여 배열형태(shape)로 가져옴.\r\n","\r\n","train 은 훈련데이터, test는 검증데이터로, x_train에는 6만개의 데이터가 있거. 각 가로와 세로가 28개씩 있다.\r\n"]},{"cell_type":"markdown","metadata":{"id":"5ByabuSxKB35"},"source":["훈련데이터에는 손글씨 그림과 그 그림이 무슨 숫자인지(정답)이 같이 들어있고, 검증데이터 또한 같이 들어있다."]},{"cell_type":"markdown","metadata":{"id":"S3yAr0zOtTQR"},"source":["y_train 은 x_train 데이터의 정답이다. 6만개가 들어있다.\r\n","\r\n",",뒤에 아무것도 안뜨는 것은 1차원 배열이라는 것을 뜻한다.\r\n"]},{"cell_type":"markdown","metadata":{"id":"nUE4tT_wt_Hq"},"source":["\r\n","---\r\n","\r\n","28*28 형태의 데이터를 인공지능 모델에 넣으려면 1차원 배열로 바꿔야한다.\r\n","\r\n","인공 신경망의 입력층에 데이터를 넣을 떄는 한줄로 만들어서 넣어야한다.\r\n","\r\n","\r\n","현재 mnist의 입력값이 28 * 28 이니 1* 784로 바꿔야한다.\r\n","\r\n","\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"8K-dKZXnwoY1"},"source":["X_Train = x_train.reshape(60000,784) #784개가 한줄(행), 60000개의 데이터(열)\r\n","X_Test = x_test.reshape(10000,784)\r\n","X_Train = X_Train.astype('float32') # 타입이 int형이라 실수형으로 바꿈. 데이터값이 0~1 사이의 값으로 정규화하려면 실수로 표현해야함. 정수로 표현안됌.\r\n","X_Test = X_Test.astype('float32')\r\n","X_Train /= 255 #검은색=0, 흰색 =255, 회색 =1~254 이니 0~1사이로 정규화를 하기위해 255로 나누어줌.\r\n","X_Test /= 255\r\n","print(X_Train.shape)\r\n","print(X_Test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hzctGG1iYEg7"},"source":["이제 여기서 각 숫자를 몇 번째라고 알려주면 인공지능은 더 높은 성능으로 분류할 수 있음.\r\n","그래서 예측이 아닌 분류 문제에서는 보통 정답 레이블을 첫번째, 두번째, 세번쨰 등 순서로 나타내도록 데이터의 형태를 바꿈. 이게 one-hot incoding임.\r\n"]},{"cell_type":"code","metadata":{"id":"STki6n7tYZ8E"},"source":["Y_train = to_categorical(y_train, 10) #수치형 데이터를 범주형 데이터로 만들어주는 케라스 내부의 유틸 도구.\r\n","Y_test = to_categorical(y_test,10) # 변경전 데이터(y_test),  원-핫 인코딩할 숫자(몇 개로 구분할건지 > 10)\r\n","print(Y_train.shape)\r\n","print(Y_test.shape)\r\n","Y_train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VDNrpd0eqphJ"},"source":["인공지능을 만들기 위해서는 데이터를 만들기 원하는 방향으로 변환하는 것이 중요한 것을 알 수  있음. 그렇기에 데이터 분석 및 변환은 인공지능 개발에서 매우 중요함."]},{"cell_type":"markdown","metadata":{"id":"rIGLWmBIrJuR"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"-lH8OPyArKyg"},"source":["<인공지능 모델 설계>"]},{"cell_type":"markdown","metadata":{"id":"VfLo3bP09ZFn"},"source":["# 모델설계"]},{"cell_type":"markdown","metadata":{"id":"aoCinlzprWe6"},"source":["4개의 층으로 만들거임. 입력층, 은닉층, 은닉층, 출력층\r\n","\r\n","입력층 뉴런의 수는 28 * 28이니 784임. 28 * 28개의 픽셀로 이루어진 숫자를 한줄로 바꾼거임.\r\n","\r\n","첫번째 은닉층의 노드 수는 512개, 두번째 은닉층의 노드 수는 256개, 세번째 결과층의 노드수는 10개로 설정함.(마지막은 0~9이니 10개)\r\n","\r\n","활성화 함수는 렐루(ReLU)함수 사용하고, 마지막은 소프트맥스(softmax)함수를 사용할거임.\r\n","\r\n","(ReLU - 0보다 작은값이 입력되면 0을 반환, 0보다 큰 값이 입력되면 그 값을 그대로 반환.\r\n","\r\n","softmax - 0~1 사이의 값으로 모두 정규화 시킴. 모든 출력값의 합이 1이 되게 만드는 활성화 함수임. 분류문제에서 어떤 범주를 가장 높은 확률로 예측하는지에 대해 주로 사용됌.)\r\n","\r\n","케라스는 시퀀셜 모델을 통해 쉽게 개발할 수록 도와줌."]},{"cell_type":"code","metadata":{"id":"9sQe8Meg2Pcw"},"source":["model = Sequential()  #모델은 시퀀셜 방식\r\n","model.add(Dense(512, input_shape = (784, ))) #첫번째 인자는 해당 은닉층의 노드 수, 두번째 인자는 입력하는 데이터의 형태.\r\n","model.add(Activation('relu'))\r\n","model.add(Dense(256)) #두번째부터는 입력받는 노드 설정 안해도됌. 케라스를 사용하는 이유임.\r\n","model.add(Activation('relu'))\r\n","model.add(Dense(10))\r\n","model.add(Activation('softmax'))\r\n","\r\n","model.summary() # 모델 확인"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QhcDGrG76Omv"},"source":["Layer 은 레이어를 표시해주는 거고,\r\n","\r\n","Output Shape는 레이어의 모습을 나타내주는 거고,\r\n","\r\n","Param은 각 노드와 편향을 연결하는 가중치의 수를 나타내는 것임.\r\n"]},{"cell_type":"markdown","metadata":{"id":"1ZzFyNif9qtO"},"source":["첫번째 레이어는 512개의 노드로 이루어짐.\r\n","784개의 입력층 에서 512개의 은닉층으로 각각 연결되어 있기에 가중치는 784 * 512 이고, 은닉층의 각 노드 수만큼 편향이 있기에 편향은 512임.\r\n","\r\n","따라서 784 * 512 + 512 이므로 401920개의 파라미터로 이루어져 있음.\r\n","\r\n","다음 레이어도 마찬가지로 512 * 256 + 256 = 131328\r\n","\r\n","마지막 레이어도 256 * 10 + 10 이므로 2570 이 나옴."]},{"cell_type":"markdown","metadata":{"id":"zH9eBZMF-wg8"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"VEpJ8_Kt-uB_"},"source":["# < 모델 학습>"]},{"cell_type":"markdown","metadata":{"id":"8HNSH9RSsvCl"},"source":["이제 모델을 설계했으니 모델을 실행해 보아야함.\r\n","\r\n","심층 신경망에 데이터를 흘려보내 정답을 예측할수 있게 신경망을 학습하는 과정이 필요함. (딥러닝)\r\n","\r\n","신경망이 예측한 결과와 실제 정답을 비교, 오차있으면 신경망을 다시 학습.\r\n","웬만하면 오차가 0이 나오는 일이 거의 없음. 그래서 보통 학습시키는 횟수를 정해줘서 그만큼만 학습시킴.\r\n","\r\n","신경망을 잘 학습시키려면 신경망이 분류한 값과 실제 값의 오차부터 계산해야함.\r\n","\r\n","오차줄이는 방법 -경사 하강법.\r\n","\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"oUHchfS7tSKL"},"source":["model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n","model.fit(X_Train, Y_train, batch_size=128, epochs=10, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n110eo0XwaMW"},"source":["loss = 오차값\r\n","\r\n","accuracy = 정확도\r\n","\r\n","loss는 Epoch가 증가할 수록 줄어들고 accuracy는 증가하는 것을 확인할 수 있다.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"lwfqlPUUxLDC"},"source":["compile 함수는 케라스에서 제공하는 함수로, 심층 신경망의 학습하는 방법을 정하는 명령어 이다.\r\n","\r\n","1. 오차값을 계산하는 방법을 알려줘야함.\r\n","    10개중 하나로 분류하는 것이니 다중 분류 문제이다. 따라서 categorical_crossentropy 방법으로 설정해준다.\r\n","\r\n","2. 오차를 줄이는 방법을 알려줘야함.\r\n","    오차를 줄이기 위해 optimizer의 adam 방법을 사용함. \r\n","\r\n","딥러닝을 통해 인공지능 모델 학습시킬때, 오차를 줄이기 위해 경사 하강법 알고리즘을 사용함. 이때 경사 하강법을 어떤 방식으로 사용할지 여러 알고리즘 있는데 이 알고리즘들을 케라스에서 모아 놓은 것이 옵티마이저 라이브러리임.\r\n","옵티마이저 종류에는 adam뿐만 아니라 확률적 경사 하강법(SGD) 등이 있음.\r\n","\r\n","3. 학습 결과를 어떻게 확인할지 알려줘야함.\r\n","    정확도(Accuracy)는 실제 6만개 데이터의 예측 결과와 실제 값을 비교하고 정답 비율을 알려줌.\r\n","    "]},{"cell_type":"markdown","metadata":{"id":"ngC-o2UbyQTz"},"source":["이제 심층 신경망의 학습하는 방법을 정했으니 fit이라는 케라스의 학습 명령어를 사용해 학습을 시킴.\r\n","\r\n","1. 입력할 데이터를 정해야함.\r\n","    X_Train , Y_train 데이터를 사용해서 인공지능 모델을 학습하니 이 두개를 넣어줌.\r\n","\r\n","2. 배치사이즈를 정해야함.\r\n","    Batch_Size 는 인공지능 모델이 한번에 학습하는 데이터 수 임.\r\n","    한번에 128개 데이터를 학습 시킨거임.\r\n","\r\n","3. 에포크를 정해야함.\r\n","    Epochs는 모든 데이터를 한번 학습하는 것을 의미함.\r\n","    모든 데이터를 10번 반복 시킬려고 epochs =10, verbose =1 로 설정함\r\n","    verbose는 케라스 fit 함수의 결괏값을 출력하는 방법임.\r\n","    0, 1, 2 중 하나로 결정할 수 있음.\r\n","\r\n","    - verbose = 0 : 아무런 표시 X\r\n","    - verbose = 1 : 에포크별 진행 사항 보여줌\r\n","    - verbose = 3 : 에포크별 학습 결과 보여줌."]},{"cell_type":"markdown","metadata":{"id":"booKeKWS1Ar8"},"source":["---\r\n","# <모델 정확도 확인>\r\n"]},{"cell_type":"markdown","metadata":{"id":"tI-r3nfg1HSS"},"source":["모델을 설계하고, 학습을 했으면 다음은 성능을 확인해 보아야한다.\r\n","인공지능 모델이 얼마나 잘 학습하는지, 검증 데이터를 얼마나 잘 맞추는지 확인해봤다.\r\n"]},{"cell_type":"code","metadata":{"id":"UEl88sWhgDzH"},"source":["model.evaluate(X_Test, Y_test)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s4va27NghI0g"},"source":["케라스의 evakuate 함수는 모델의 정확도를 평가하는 함수임.\r\n","첫번째 인자는 테스트할 데이터,\r\n","두번째 인자는 테스트할 데이터의 정답임.\r\n","loss(오차값)은 0 ~ 1 사이 값으로 0에 가까울 수록 오차가 적은것임.\r\n","accuracy(정확도) 또한 0~1 사이 값으로 1에 가까울 수록 정확한 거임.\r\n"]},{"cell_type":"markdown","metadata":{"id":"8YjspBWlhq-P"},"source":["#모델 학습 결과 확인"]},{"cell_type":"code","metadata":{"id":"m5nn1vPkn6lk"},"source":["predicted_classes = np.argmax(model.predict(X_Test), axis=1)\r\n","correct_indices = np.nonzero(predicted_classes == y_test)[0]\r\n","incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xzruBESzmN1F"},"source":["predict 는 결과를 예측하는 함수임.\r\n","X_Test 의 데이터 개수가 만개였으니 예측값도 만개나옴.\r\n","\r\n","numpy의 argmax 함수를 이용해서 여러 데이터 중 가장 큰 값의 위치를 반환함.\r\n","argmax를 쓸 때는, 열에서 가장 큰 값을 구할지, 행에서 가장 큰 값을 구할지 설정해야함.\r\n","이 때 기준을 정해주는 것이 axis 임. axis=0이면 열에서 가장 큰 수를 고르고, axis=1이면 행에서 가장 큰 수를 고름.\r\n","\r\n","nonzero는 넘파이 배열에서 0이 아닌 값을 찾는 것임. "]},{"cell_type":"code","metadata":{"id":"kPxUAjK_ocJx"},"source":["plt.figure()\r\n","for i in range(9):\r\n","    plt.subplot(3,3,i+1)\r\n","    correct = correct_indices[i]\r\n","    plt.imshow(X_Test[correct].reshape(28,28), cmap='gray')\r\n","    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\r\n","plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QvhP9yhGhtWB"},"source":["matplotlib 라이브러리를 통해 그래프를 그림.\r\n","figure()은 그래프를 그리겠다는 명령임. 그래프를 그리려면 그릴 준비를 해야함. 그 준비하는 명령이 figure함수임.\r\n","\r\n","subplot은 그림의 순서를 정해주는 함수임. \r\n","첫번째 인자는 그림의 가로 개수,\r\n","두번째 인자는 그림의 새로 개수,\r\n","세번째 인자는 그림의 순서임.\r\n","\r\n","imshow 함수는 어떤 이미지를 보여줄지에 대한 내용을 담고 있음.\r\n","현재 데이터는 1차원 배열로 되어있으니 reshape로 28 * 28 형태로 바꾸어줌. \r\n","그림을 회색조로 나타내려고 cmap = 'gray' 로 설정함.\r\n","\r\n","title 함수는 그림에 대한 설명을 넣는 함수임.\r\n","format함수를 사용해 {} 안에 값을 넣음.\r\n","\r\n","화면에 그림을 보여주는 tight_layout을 사용함.\r\n","\r\n","아래는 틀린 데이터 들을 출력하는 코드임.\r\n"]},{"cell_type":"code","metadata":{"id":"bbS1S4X0jUVR"},"source":["plt.figure()\r\n","for i in range(9):\r\n","    plt.subplot(3,3,i+1)\r\n","    incorrect = incorrect_indices[i]\r\n","    plt.imshow(X_Test[incorrect].reshape(28,28), cmap='gray')\r\n","    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\r\n","plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8DrmmiZsjoBj"},"source":["인공지능의 성능이 좋아 보이지 않음.\r\n","왜냐하면 모델 학습이 잘 되지 않아서임.\r\n","인공지능 모델 학습이 잘 이루어지기 위해선 모델의 학습 횟수를 늘려주어야함.\r\n","\r\n","근데 모델의 학습 횟수만 무작정 늘린다고 인공지능 성능이 꾸준히 높아지는건 아님.\r\n","과적합(overfitting) 문제가 일어날 수 있기 때문.\r\n","\r\n","여기서 오버피팅은 인공지능이 훈련 데이터에만 최적화되서 훈련 데이터만 잘 구분하고, 새로운 데이터인 검증 데이터를 인공지능 모델에 넣으면 구분하지 못하는 현상이 일어날 수 있음. 즉, 성능이 나빠지는 거임.\r\n","\r\n","그래서 인공지능 모델을 학습시킬 때에는 무조건 많이가 아닌, 얼마만큼 학습 시켜야 제일 좋을지 결정할 수 있어야하고, 이게 인공지능 모델 설계에서 중요한 부분임.\r\n"]}]}